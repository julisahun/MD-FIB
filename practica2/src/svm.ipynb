{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INSTALL PACKAGES AND IMPORT THEM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                     # Llibreria matemÃ tica\n",
    "import matplotlib.pyplot as plt        # Per mostrar plots\n",
    "import sklearn as sk                         # Llibreia de DM\n",
    "import pandas as pd   # Optional: good package for manipulating data \n",
    "import sklearn.datasets as ds            # Per carregar mÃ©s facilment el dataset digits\n",
    "import sklearn.model_selection as cv    # Pel Cross-validation\n",
    "import sklearn.neighbors as nb           # Per fer servir el knn\n",
    "from sklearn.model_selection import cross_val_score  \n",
    "%matplotlib inline     "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LOAD DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "  global df\n",
    "  try: \n",
    "    df = pd.read_csv(\"../src/preprocessed.csv\")\n",
    "  except FileNotFoundError:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    df=pd.read_csv('/content/drive/MyDrive/MD/Laboratori/Practica 2/data/smoking.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height(cm)</th>\n",
       "      <th>weight(kg)</th>\n",
       "      <th>eyesight(left)</th>\n",
       "      <th>eyesight(right)</th>\n",
       "      <th>hearing(left)</th>\n",
       "      <th>hearing(right)</th>\n",
       "      <th>systolic</th>\n",
       "      <th>fasting blood sugar</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>triglyceride</th>\n",
       "      <th>HDL</th>\n",
       "      <th>hemoglobin</th>\n",
       "      <th>Urine protein</th>\n",
       "      <th>serum creatinine</th>\n",
       "      <th>ALT</th>\n",
       "      <th>Gtp</th>\n",
       "      <th>dental caries</th>\n",
       "      <th>tartar</th>\n",
       "      <th>smoking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>155</td>\n",
       "      <td>60</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>19.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>160</td>\n",
       "      <td>60</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55</td>\n",
       "      <td>170</td>\n",
       "      <td>60</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>165</td>\n",
       "      <td>70</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>155</td>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  height(cm)  weight(kg)  eyesight(left)  eyesight(right)   \n",
       "0   40         155          60             1.2              1.0  \\\n",
       "1   40         160          60             0.8              0.6   \n",
       "2   55         170          60             0.8              0.8   \n",
       "3   40         165          70             1.5              1.5   \n",
       "4   40         155          60             1.0              1.0   \n",
       "\n",
       "   hearing(left)  hearing(right)  systolic  fasting blood sugar  Cholesterol   \n",
       "0            1.0             1.0     114.0                 94.0        215.0  \\\n",
       "1            1.0             1.0     119.0                130.0        192.0   \n",
       "2            1.0             1.0     138.0                 89.0        242.0   \n",
       "3            1.0             1.0     100.0                 96.0        322.0   \n",
       "4            1.0             1.0     120.0                 80.0        184.0   \n",
       "\n",
       "   triglyceride   HDL  hemoglobin  Urine protein  serum creatinine   ALT   \n",
       "0          82.0  73.0        12.9            1.0               0.7  19.0  \\\n",
       "1         115.0  42.0        12.7            1.0               0.6  19.0   \n",
       "2         182.0  55.0        15.8            1.0               1.0  16.0   \n",
       "3         254.0  45.0        14.7            1.0               1.0  26.0   \n",
       "4          74.0  62.0        12.5            1.0               0.6  14.0   \n",
       "\n",
       "    Gtp  dental caries  tartar  smoking  \n",
       "0  27.0          False    True    False  \n",
       "1  18.0          False    True    False  \n",
       "2  22.0          False   False     True  \n",
       "3  18.0          False    True    False  \n",
       "4  22.0          False   False    False  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalisation of data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height(cm)</th>\n",
       "      <th>weight(kg)</th>\n",
       "      <th>eyesight(left)</th>\n",
       "      <th>eyesight(right)</th>\n",
       "      <th>hearing(left)</th>\n",
       "      <th>hearing(right)</th>\n",
       "      <th>systolic</th>\n",
       "      <th>fasting blood sugar</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>triglyceride</th>\n",
       "      <th>HDL</th>\n",
       "      <th>hemoglobin</th>\n",
       "      <th>Urine protein</th>\n",
       "      <th>serum creatinine</th>\n",
       "      <th>ALT</th>\n",
       "      <th>Gtp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>53956.000000</td>\n",
       "      <td>53956.000000</td>\n",
       "      <td>53956.000000</td>\n",
       "      <td>53956.000000</td>\n",
       "      <td>53956.000000</td>\n",
       "      <td>53956.000000</td>\n",
       "      <td>53956.000000</td>\n",
       "      <td>53956.000000</td>\n",
       "      <td>53956.000000</td>\n",
       "      <td>53956.000000</td>\n",
       "      <td>53956.000000</td>\n",
       "      <td>53956.000000</td>\n",
       "      <td>53956.000000</td>\n",
       "      <td>53956.000000</td>\n",
       "      <td>53956.000000</td>\n",
       "      <td>53956.000000</td>\n",
       "      <td>53956.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>43.239306</td>\n",
       "      <td>164.884628</td>\n",
       "      <td>66.073282</td>\n",
       "      <td>1.021260</td>\n",
       "      <td>1.016777</td>\n",
       "      <td>1.019442</td>\n",
       "      <td>1.019998</td>\n",
       "      <td>121.204259</td>\n",
       "      <td>99.076118</td>\n",
       "      <td>197.295982</td>\n",
       "      <td>126.902254</td>\n",
       "      <td>57.358885</td>\n",
       "      <td>14.641085</td>\n",
       "      <td>1.085996</td>\n",
       "      <td>0.884039</td>\n",
       "      <td>27.197883</td>\n",
       "      <td>40.092112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.016945</td>\n",
       "      <td>9.123537</td>\n",
       "      <td>12.866585</td>\n",
       "      <td>0.465187</td>\n",
       "      <td>0.472137</td>\n",
       "      <td>0.138073</td>\n",
       "      <td>0.139994</td>\n",
       "      <td>13.542347</td>\n",
       "      <td>20.673482</td>\n",
       "      <td>36.166005</td>\n",
       "      <td>71.961424</td>\n",
       "      <td>14.764334</td>\n",
       "      <td>1.566888</td>\n",
       "      <td>0.399633</td>\n",
       "      <td>0.216193</td>\n",
       "      <td>31.352849</td>\n",
       "      <td>50.375825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>14.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>15.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>65.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>505.000000</td>\n",
       "      <td>445.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>618.000000</td>\n",
       "      <td>21.100000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>2914.000000</td>\n",
       "      <td>999.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age    height(cm)    weight(kg)  eyesight(left)   \n",
       "count  53956.000000  53956.000000  53956.000000    53956.000000  \\\n",
       "mean      43.239306    164.884628     66.073282        1.021260   \n",
       "std       11.016945      9.123537     12.866585        0.465187   \n",
       "min       20.000000    135.000000     30.000000        0.100000   \n",
       "25%       35.000000    160.000000     55.000000        0.800000   \n",
       "50%       40.000000    165.000000     65.000000        1.000000   \n",
       "75%       50.000000    170.000000     75.000000        1.200000   \n",
       "max       65.000000    190.000000    135.000000        9.900000   \n",
       "\n",
       "       eyesight(right)  hearing(left)  hearing(right)      systolic   \n",
       "count     53956.000000   53956.000000    53956.000000  53956.000000  \\\n",
       "mean          1.016777       1.019442        1.019998    121.204259   \n",
       "std           0.472137       0.138073        0.139994     13.542347   \n",
       "min           0.100000       1.000000        1.000000     71.000000   \n",
       "25%           0.800000       1.000000        1.000000    112.000000   \n",
       "50%           1.000000       1.000000        1.000000    120.000000   \n",
       "75%           1.200000       1.000000        1.000000    130.000000   \n",
       "max           9.900000       2.000000        2.000000    240.000000   \n",
       "\n",
       "       fasting blood sugar   Cholesterol  triglyceride           HDL   \n",
       "count         53956.000000  53956.000000  53956.000000  53956.000000  \\\n",
       "mean             99.076118    197.295982    126.902254     57.358885   \n",
       "std              20.673482     36.166005     71.961424     14.764334   \n",
       "min              46.000000     55.000000      8.000000      4.000000   \n",
       "25%              89.000000    172.000000     74.000000     47.000000   \n",
       "50%              95.000000    195.000000    108.000000     55.000000   \n",
       "75%             103.000000    220.000000    160.000000     66.000000   \n",
       "max             505.000000    445.000000    999.000000    618.000000   \n",
       "\n",
       "         hemoglobin  Urine protein  serum creatinine           ALT   \n",
       "count  53956.000000   53956.000000      53956.000000  53956.000000  \\\n",
       "mean      14.641085       1.085996          0.884039     27.197883   \n",
       "std        1.566888       0.399633          0.216193     31.352849   \n",
       "min        4.900000       1.000000          0.100000      1.000000   \n",
       "25%       13.600000       1.000000          0.800000     15.000000   \n",
       "50%       14.800000       1.000000          0.900000     21.000000   \n",
       "75%       15.800000       1.000000          1.000000     31.000000   \n",
       "max       21.100000       6.000000         11.600000   2914.000000   \n",
       "\n",
       "                Gtp  \n",
       "count  53956.000000  \n",
       "mean      40.092112  \n",
       "std       50.375825  \n",
       "min        1.000000  \n",
       "25%       17.000000  \n",
       "50%       26.000000  \n",
       "75%       44.000000  \n",
       "max      999.000000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                      int64\n",
       "height(cm)               int64\n",
       "weight(kg)               int64\n",
       "eyesight(left)         float64\n",
       "eyesight(right)        float64\n",
       "hearing(left)          float64\n",
       "hearing(right)         float64\n",
       "systolic               float64\n",
       "fasting blood sugar    float64\n",
       "Cholesterol            float64\n",
       "triglyceride           float64\n",
       "HDL                    float64\n",
       "hemoglobin             float64\n",
       "Urine protein          float64\n",
       "serum creatinine       float64\n",
       "ALT                    float64\n",
       "Gtp                    float64\n",
       "dental caries            int64\n",
       "tartar                   int64\n",
       "smoking                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In order to apply SVM, we need our data to be numerical and normalised\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Transform boolean types into numerical\n",
    "df['dental caries'] = df['dental caries'].astype(int)\n",
    "df['tartar'] = df['tartar'].astype(int)\n",
    "df['smoking'] = df['smoking'].astype(int)\n",
    "\n",
    "# Spliting dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop(columns=['smoking'], axis=1)\n",
    "y = df['smoking']\n",
    "X_train, X_test, y_train, y_test = cv.train_test_split(X, y, test_size=.3, stratify = y,random_state=1)\n",
    "\n",
    "# Normalisation \n",
    "scaler = MinMaxScaler(feature_range=(-1, 1)).fit(X_train)\n",
    "X_train_n = scaler.fit_transform(X_train)\n",
    "X_test_n = scaler.transform(X_test)\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear SVM**\n",
    "\n",
    "Let's try an SVM with default parameters. Linear means that we are not using any kernel to move the data to a higher dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JULIIIIII AQUEST QUADRADET :)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#knc = LinearSVC() \n",
    "knc = SVC(kernel='linear')\n",
    "knc.fit(X_train, y_train)\n",
    "pred=knc.predict(X_test)\n",
    "print(\"Confusion matrix on test set:\\n\",sklearn.metrics.confusion_matrix(y_test, pred))\n",
    "print(\"\\nAccuracy on test set: \",sklearn.metrics.accuracy_score(y_test, pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad results. However, the linear SVM has parameter C that has to be adjusted. We will use GridSearch method to find the optimal value of C like we did in a previous notebook with the k value of the KNN algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of C values to test. We usualy test diverse orders of magnitude\n",
    "#Cs = np.logspace(-3, 11, num=15, base=10.0)\n",
    "Cs = np.logspace(-3, 5, num=9, base=10.0)\n",
    "\n",
    "param_grid = {'C': Cs}\n",
    "#grid_search = GridSearchCV(LinearSVC(), param_grid, cv=10)\n",
    "grid_search = GridSearchCV(SVC(kernel='linear'), param_grid, cv=10)\n",
    "grid_search.fit(X_train,y_train)\n",
    "\n",
    "# Let's plot the 10-fold cross.validation accuracy deppending on C\n",
    "scores = grid_search.cv_results_['mean_test_score']\n",
    "plt.semilogx(Cs,scores)\n",
    "plt.show()\n",
    "\n",
    "parval=grid_search.best_params_\n",
    "cvacc = cross_val_score(SVC(C=parval['C'],kernel='linear'), X=X_train,  y=y_train, cv=10, scoring='accuracy')\n",
    "print('Acc. 10-fold cross on train data= ', cvacc.mean())\n",
    "\n",
    "\n",
    "# Let's apply the best C parameter found to the test set\n",
    "\n",
    "#knc = LinearSVC(C=parval['C']) \n",
    "knc = SVC(C=parval['C'],kernel='linear')\n",
    "knc.fit(X_train, y_train)\n",
    "pred=knc.predict(X_test)\n",
    "print(\"\\nConfusion matrix on test set:\\n\",sklearn.metrics.confusion_matrix(y_test, pred))\n",
    "print(\"\\nAccuracy on test set: \",sklearn.metrics.accuracy_score(y_test, pred))\n",
    "print(\"\\nBest value of parameter C found: \",parval)\n",
    "print(\"\\nNumber of supports: \",np.sum(knc.n_support_), \"(\",np.sum(np.abs(knc.dual_coef_)==parval['C']) ,\"of them have slacks)\")\n",
    "print(\"Prop. of supports: \",np.sum(knc.n_support_)/X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "def plot_validation_curve(parameter_values, train_scores, validation_scores):\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    validation_scores_mean = np.mean(validation_scores, axis=1)\n",
    "    validation_scores_std = np.std(validation_scores, axis=1)\n",
    "\n",
    "    plt.fill_between(parameter_values, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(parameter_values, validation_scores_mean - validation_scores_std,\n",
    "                     validation_scores_mean + validation_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(parameter_values, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(parameter_values, validation_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "    plt.ylim(validation_scores_mean.min() - .1, train_scores_mean.max() + .1)\n",
    "    plt.legend(loc=4)\n",
    "\n",
    "\n",
    "training_scores, test_scores = validation_curve(SVC(kernel='linear'), X_train, y_train, param_name=\"C\", param_range=Cs,cv=10)\n",
    "plot_validation_curve(range(len(Cs)), training_scores, test_scores)\n",
    "plt.xticks(range(len(Cs)), Cs,rotation='vertical');\n",
    "plt.ylim([0.6, 1])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Polynomial kernels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knc = SVC(kernel='poly',degree =2) \n",
    "knc.fit(X_train, y_train)\n",
    "pred=knc.predict(X_test)\n",
    "print(\"Confusion matrix on test set:\\n\",sklearn.metrics.confusion_matrix(y_test, pred))\n",
    "print(\"\\nAccuracy on test set: \",sklearn.metrics.accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = np.logspace(-3, 11, num=15, base=10.0)\n",
    "\n",
    "param_grid = {'C': Cs}\n",
    "grid_search = GridSearchCV(SVC(kernel='poly',degree =2) , param_grid, cv=10)\n",
    "grid_search.fit(X_train,y_train)\n",
    "\n",
    "scores = grid_search.cv_results_['mean_test_score']\n",
    "\n",
    "plt.semilogx(Cs,scores)\n",
    "plt.show()\n",
    "\n",
    "parval=grid_search.best_params_\n",
    "\n",
    "cvacc = cross_val_score(SVC(kernel='poly',degree =2,C=parval['C']) , X=X_train,  y=y_train, cv=10, scoring='accuracy')\n",
    "print('Acc. 10-fold cross on train data= ', cvacc.mean())\n",
    "\n",
    "\n",
    "knc = SVC(kernel='poly',degree =2,C=parval['C']) \n",
    "knc.fit(X_train, y_train)\n",
    "pred=knc.predict(X_test)\n",
    "print(\"\\nConfusion matrix on test set:\\n\",sklearn.metrics.confusion_matrix(y_test, pred))\n",
    "print(\"\\nAccuracy on test set: \",sklearn.metrics.accuracy_score(y_test, pred))\n",
    "print(\"\\nBest combination of parameters found: \",parval)\n",
    "print(\"\\nNumber of supports: \",np.sum(knc.n_support_), \"(\",np.sum(np.abs(knc.dual_coef_)==parval['C']) ,\"of them have slacks)\")\n",
    "print(\"Prop. of supports: \",np.sum(knc.n_support_)/X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knc = SVC(kernel='poly',degree =3) \n",
    "knc.fit(X_train, y_train)\n",
    "pred=knc.predict(X_test)\n",
    "print(\"Confusion matrix on test set:\\n\",sklearn.metrics.confusion_matrix(y_test, pred))\n",
    "print(\"\\nAccuracy on test set: \",sklearn.metrics.accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = np.logspace(-3, 11, num=15, base=10.0)\n",
    "\n",
    "param_grid = {'C': Cs}\n",
    "grid_search = GridSearchCV(SVC(kernel='poly',degree =3) , param_grid, cv=10)\n",
    "grid_search.fit(X_train,y_train)\n",
    "\n",
    "scores = grid_search.cv_results_['mean_test_score']\n",
    "\n",
    "plt.semilogx(Cs,scores)\n",
    "plt.show()\n",
    "\n",
    "parval=grid_search.best_params_\n",
    "\n",
    "cvacc = cross_val_score(SVC(kernel='poly',degree =3,C=parval['C']) , X=X_train,  y=y_train, cv=10, scoring='accuracy')\n",
    "print('Acc. 10-fold cross on train data= ', cvacc.mean())\n",
    "\n",
    "knc = SVC(kernel='poly',degree =3,C=parval['C']) \n",
    "knc.fit(X_train, y_train)\n",
    "pred=knc.predict(X_test)\n",
    "print(\"\\nConfusion matrix on test set:\\n\",sklearn.metrics.confusion_matrix(y_test, pred))\n",
    "print(\"\\nBest combination of parameters found: \",parval)\n",
    "print(\"\\nAccuracy on test set: \",sklearn.metrics.accuracy_score(y_test, pred))\n",
    "print(\"\\nNumber of supports: \",np.sum(knc.n_support_), \"(\",np.sum(np.abs(knc.dual_coef_)==parval['C']) ,\"of them have slacks)\")\n",
    "print(\"Prop. of supports: \",np.sum(knc.n_support_)/X_train.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RBF KERNEL**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "knc = SVC() \n",
    "knc.fit(X_train, y_train)\n",
    "pred=knc.predict(X_test)\n",
    "print(\"Confusion matrix on test set:\\n\",sklearn.metrics.confusion_matrix(y_test, pred))\n",
    "print(\"\\nAccuracy on test set: \",sklearn.metrics.accuracy_score(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values we will test for each parameter. When observin results, consider the limits of the \n",
    "# values tested and increase them if necessary \n",
    "gammas = [0.000001,0.00001, 0.0001,0.001,0.01,0.1,1,10]\n",
    "Cs = np.logspace(-1, 6, num=8, base=10.0)\n",
    "\n",
    "param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=10)\n",
    "grid_search.fit(X_train,y_train)\n",
    "parval=grid_search.best_params_\n",
    "\n",
    "# We'll show in a grid, the accuracy for each combination of parameters tester\n",
    "scores = grid_search.cv_results_['mean_test_score']\n",
    "scores = np.array(scores).reshape(len(param_grid['C']), len(param_grid['gamma']))\n",
    "\n",
    "plt.matshow(scores)\n",
    "plt.xlabel('gamma')\n",
    "plt.ylabel('C')\n",
    "plt.colorbar()\n",
    "plt.xticks(np.arange(len(param_grid['gamma'])), param_grid['gamma'],rotation='vertical')\n",
    "plt.yticks(np.arange(len(param_grid['C'])), param_grid['C'])\n",
    "plt.show()\n",
    "parval=grid_search.best_params_\n",
    "print(\"\\nBest combination of parameters found: \",parval)\n",
    "\n",
    "\n",
    "cvacc = cross_val_score(SVC(C=parval['C'], gamma=parval['gamma']) , X=X_train,  y=y_train, cv=10, scoring='accuracy')\n",
    "print('\\nAcc. 10-fold cross on train data= ', cvacc.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's apply the best combination of parameters found to the test set\n",
    "\n",
    "knc = SVC(C=parval['C'], gamma=parval['gamma']) \n",
    "knc.fit(X_train, y_train)\n",
    "pred=knc.predict(X_test)\n",
    "\n",
    "print(\"Confusion matrix on test set:\\n\",sklearn.metrics.confusion_matrix(y_test, pred))\n",
    "print(\"\\nAccuracy on test set: \",sklearn.metrics.accuracy_score(y_test, pred))\n",
    "print(\"\\nNumber of supports: \",np.sum(knc.n_support_), \"(\",np.sum(np.abs(knc.dual_coef_)==parval['C']) ,\"of them have slacks)\")\n",
    "print(\"Prop. of supports: \",np.sum(knc.n_support_)/X_train.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Appendix: performance metha-methods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf=ExtraTreesClassifier(n_estimators=200,random_state=1).fit(X_train, y_train)\n",
    "pred=clf.predict(X_test)\n",
    "print(\"Confusion matrix on test set:\\n\",sklearn.metrics.confusion_matrix(y_test, pred))\n",
    "print(\"\\nAccuracy on test set: \",sklearn.metrics.accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "clf=AdaBoostClassifier(n_estimators=200,random_state=1).fit(X_train, y_train)\n",
    "pred=clf.predict(X_test)\n",
    "print(\"Confusion matrix on test set:\\n\",sklearn.metrics.confusion_matrix(y_test, pred))\n",
    "print(\"\\nAccuracy on test set: \",sklearn.metrics.accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "clf=BaggingClassifier(n_estimators=200,max_features=0.35,random_state=1).fit(X_train, y_train)\n",
    "pred=clf.predict(X_test)\n",
    "print(\"Confusion matrix on test set:\\n\",sklearn.metrics.confusion_matrix(y_test, pred))\n",
    "print(\"\\nAccuracy on test set: \",sklearn.metrics.accuracy_score(y_test, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
